{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dbbf555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install neuralforecast datasetsforecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf1cc4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install horovod==0.26.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69b7c099",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33357cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/lightning_fabric/__init__.py:29: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  __import__(\"pkg_resources\").declare_namespace(__name__)\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from datasetsforecast.long_horizon import LongHorizon\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from typing import Optional\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from dataset import LongHorizonUnivariateDataModule, LongHorizonUnivariateDataset\n",
    "import pytorch_lightning as pl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1647f79c-9a8d-4c23-9c20-f35a8025b8f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/downloads/emhires_pv/EMHIRES_PVGIS_TSh_CF_n2_19862015_reformatt.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:1\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/excel/_base.py:495\u001b[0m, in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[1;32m    494\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 495\u001b[0m     io \u001b[38;5;241m=\u001b[39m \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[1;32m    502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    503\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    504\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    505\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/excel/_base.py:1550\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m   1548\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1549\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1550\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[43minspect_excel_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[1;32m   1552\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1553\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1554\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1555\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel file format cannot be determined, you must specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1556\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man engine manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1557\u001b[0m         )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/excel/_base.py:1402\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[1;32m   1400\u001b[0m     content_or_path \u001b[38;5;241m=\u001b[39m BytesIO(content_or_path)\n\u001b[0;32m-> 1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1403\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m   1404\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[1;32m   1405\u001b[0m     stream \u001b[38;5;241m=\u001b[39m handle\u001b[38;5;241m.\u001b[39mhandle\n\u001b[1;32m   1406\u001b[0m     stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[1;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/downloads/emhires_pv/EMHIRES_PVGIS_TSh_CF_n2_19862015_reformatt.xlsx'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df = pd.read_excel('data/downloads/emhires_pv/EMHIRES_PVGIS_TSh_CF_n2_19862015_reformatt.xlsx')\n",
    "df.drop('SE33', axis=1, inplace=True)\n",
    "df['time_step'] = pd.date_range(start='1986-01-01', periods=len(df), freq='h')\n",
    "df = df.rename({'time_step': 'ds'}, axis=1).set_index('ds')\n",
    "df.to_parquet('data/emhires/pv_n2.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4b20d89-091b-4e2b-a99e-48b38f3c3bf2",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/downloads/emhires_pv/EMHIRES_PVGIS_TSh_CF_n2_19862015_reformatt.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:1\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/excel/_base.py:495\u001b[0m, in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[1;32m    494\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 495\u001b[0m     io \u001b[38;5;241m=\u001b[39m \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[1;32m    502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    503\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    504\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    505\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/excel/_base.py:1550\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m   1548\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1549\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1550\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[43minspect_excel_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[1;32m   1552\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1553\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1554\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1555\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel file format cannot be determined, you must specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1556\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man engine manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1557\u001b[0m         )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/excel/_base.py:1402\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[1;32m   1400\u001b[0m     content_or_path \u001b[38;5;241m=\u001b[39m BytesIO(content_or_path)\n\u001b[0;32m-> 1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1403\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m   1404\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[1;32m   1405\u001b[0m     stream \u001b[38;5;241m=\u001b[39m handle\u001b[38;5;241m.\u001b[39mhandle\n\u001b[1;32m   1406\u001b[0m     stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[1;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/downloads/emhires_pv/EMHIRES_PVGIS_TSh_CF_n2_19862015_reformatt.xlsx'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df = pd.read_excel('data/downloads/emhires_pv/EMHIRES_PVGIS_TSh_CF_n2_19862015_reformatt.xlsx')\n",
    "df.drop('SE33', axis=1, inplace=True)\n",
    "df['time_step'] = pd.date_range(start='1986-01-01', periods=len(df), freq='h')\n",
    "df = df.rename({'time_step': 'ds'}, axis=1).set_index('ds')\n",
    "df.to_parquet('data/emhires/pv_n2.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a2d15b-5836-41d9-b9b0-170766eda511",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f406ceb-716f-41bf-9740-31d4deb3f689",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_pd.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.to_csv('test_pd.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f94314-739c-4580-a692-38ad9afa19e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ce04bc-7a2a-4b31-9e20-d8053bad8455",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "a = pd.read_parquet('test_pd.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfa2281-a4ea-4d2f-820d-554b4b3a7e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5480b174-bf49-4307-80c6-b90fd4c00fa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714ce208-7c2a-4753-9fad-f686eb14670b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96a702a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn_flat_deal(batch):\n",
    "    out = {}\n",
    "    for b in batch:\n",
    "        for k, bv in b.items():\n",
    "            v = out.get(k, [])\n",
    "            v.append(bv)\n",
    "            out[k] = v\n",
    "            \n",
    "    for k,v in out.items():\n",
    "        v = np.concatenate(v)\n",
    "        if type(v[0]) not in [np.str_, pd.Timestamp]:\n",
    "            v = torch.as_tensor(v)\n",
    "        out[k] = v\n",
    "    return out\n",
    "\n",
    "class LongHorizonUnivariateDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, \n",
    "                 name: str = 'ETTm2', \n",
    "                 train_batch_size: int = 128, \n",
    "                 eval_batch_size: int = None,\n",
    "                 num_workers: int = 4,\n",
    "                 persistent_workers: bool = True,\n",
    "                 horizon_length: int = 720,\n",
    "                 history_length: int = 720,\n",
    "                 split_proportions: List[float] = [0.6, 0.2, 0.2]\n",
    "                ):\n",
    "        super().__init__()\n",
    "        self.name = name\n",
    "        self.train_batch_size = train_batch_size\n",
    "        self.eval_batch_size = train_batch_size\n",
    "        if eval_batch_size is not None:\n",
    "            self.eval_batch_size = eval_batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.persistent_workers = persistent_workers\n",
    "        self.history_length = history_length\n",
    "        self.horizon_length = horizon_length\n",
    "        self.split_proportions = np.array(split_proportions).cumsum()\n",
    "        \n",
    "        assert self.split_proportions[-1] == 1, \"Split proportions must sum up to 1\"\n",
    "\n",
    "    def prepare_data(self):\n",
    "        LongHorizon.load(directory='./data', group='ETTm2')\n",
    "\n",
    "    def setup(self, stage: str):\n",
    "        # Assign train/val datasets for use in dataloaders\n",
    "        if stage == \"fit\":\n",
    "            self.train_dataset = LongHorizonUnivariateDataset(name=self.name, split='train', \n",
    "                                                              split_start=0.0,\n",
    "                                                              split_end=self.split_proportions[0],\n",
    "                                                              horizon_length=self.horizon_length,\n",
    "                                                              history_length = self.history_length)\n",
    "            self.val_dataset = LongHorizonUnivariateDataset(name=self.name, split='val', \n",
    "                                                            split_start=self.split_proportions[0],\n",
    "                                                            split_end=self.split_proportions[1],\n",
    "                                                            horizon_length=self.horizon_length,\n",
    "                                                            history_length = self.history_length)\n",
    "        # Assign test dataset for use in dataloader(s)\n",
    "        if stage == \"test\":\n",
    "            self.test_dataset = LongHorizonUnivariateDataset(name=self.name, split='test', \n",
    "                                                             split_start=self.split_proportions[1],\n",
    "                                                             split_end=self.split_proportions[2],\n",
    "                                                             horizon_length=self.horizon_length,\n",
    "                                                             history_length = self.history_length)\n",
    "        if stage == \"predict\":\n",
    "            self.predict_dataset = LongHorizonUnivariateDataset(name=self.name, split='test', \n",
    "                                                                split_start=self.split_proportions[1],\n",
    "                                                                split_end=self.split_proportions[2],\n",
    "                                                                horizon_length=self.horizon_length,\n",
    "                                                                history_length = self.history_length)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.train_batch_size, \n",
    "                          shuffle=True, pin_memory=True, \n",
    "                          persistent_workers=self.persistent_workers,\n",
    "                          num_workers=self.num_workers, collate_fn=collate_fn_flat_deal)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.eval_batch_size, \n",
    "                          shuffle=False, pin_memory=True, \n",
    "                          persistent_workers=self.persistent_workers,\n",
    "                          num_workers=self.num_workers, collate_fn=collate_fn_flat_deal)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.eval_batch_size,\n",
    "                          shuffle=False, pin_memory=True, \n",
    "                          persistent_workers=self.persistent_workers,\n",
    "                          num_workers=self.num_workers, collate_fn=collate_fn_flat_deal)\n",
    "\n",
    "    def predict_dataloader(self):\n",
    "        return DataLoader(self.predict_dataset, batch_size=self.eval_batch_size, \n",
    "                          shuffle=False, pin_memory=True, \n",
    "                          persistent_workers=self.persistent_workers,\n",
    "                          num_workers=self.num_workers, collate_fn=collate_fn_flat_deal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ba5af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = LongHorizonUnivariateDataModule(train_batch_size=128)\n",
    "dm.prepare_data()\n",
    "dm.setup(stage='fit')\n",
    "dm.setup(stage='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46d725e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.split_proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994aed84",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = dm.train_dataloader()\n",
    "val_loader = dm.val_dataloader()\n",
    "test_loader = dm.test_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e51209",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader.dataset.time_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d650914b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in tqdm(train_loader):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0851443a",
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5484c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in tqdm(val_loader):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d83956e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in tqdm(test_loader):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebd3b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "ETTm2 = LongHorizonUnivariateDataset(name='ETTm2', split='train', split_start=0, split_end=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a90ed8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ETTm2.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f303d1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ETTm2.df.index.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58754228",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ETTm2.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b738c25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(12240-720) / 57600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed764ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "ETTm2[2*ETTm2.num_windows+ETTm2.num_windows-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b702313",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn_flat_deal(batch):\n",
    "    out = {}\n",
    "    for b in batch:\n",
    "        for k, bv in b.items():\n",
    "            v = out.get(k, [])\n",
    "            v.append(bv)\n",
    "            out[k] = v\n",
    "            \n",
    "    for k,v in out.items():\n",
    "        v = np.concatenate(v)\n",
    "        if type(v[0]) not in [np.str_, pd.Timestamp]:\n",
    "            v = torch.as_tensor(v)\n",
    "        out[k] = v\n",
    "    return out\n",
    "\n",
    "dl = DataLoader(ETTm2, batch_size=512, \n",
    "                          shuffle=True, pin_memory=True, \n",
    "                          persistent_workers=True,\n",
    "                          num_workers=4, collate_fn=collate_fn_flat_deal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b01598d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in tqdm(dl):\n",
    "    \n",
    "    a=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18916e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "b['history'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5a60bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_df.ds = pd.to_datetime(Y_df.ds)\n",
    "# Y_df = Y_df.pivot(index='ds', columns='unique_id', values='y')\n",
    "\n",
    "Y_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c8882a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec289272",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5fa070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from neuralforecast import TimeSeriesDataset\n",
    "\n",
    "from neuralforecast.tsdataset import TimeSeriesDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1f1d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds, uids, last_dates, ds_sort  = TimeSeriesDataset.from_df(Y_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ecb40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[0]['temporal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb21fa0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800e51af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
