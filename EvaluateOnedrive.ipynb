{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69b7c099",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96ea3323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repair archive\n",
    "# sudo zip -FF T162.zip --out T162Repaired.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33357cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/lightning_fabric/__init__.py:29: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  __import__(\"pkg_resources\").declare_namespace(__name__)\n",
      "/opt/conda/lib/python3.10/site-packages/statsforecast/utils.py:231: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  \"ds\": pd.date_range(start=\"1949-01-01\", periods=len(AirPassengers), freq=\"M\"),\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from datasetsforecast.long_horizon import LongHorizon\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from typing import Optional\n",
    "\n",
    "import os, pathlib\n",
    "from glob import glob\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from dataset import LongHorizonUnivariateDataModule, LongHorizonUnivariateDataset\n",
    "from dataset import ElectricityUnivariateDataModule, ElectricityUnivariateDataset\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from omegaconf import OmegaConf\n",
    "from utils.model_factory import instantiate\n",
    "\n",
    "from onedrivedownloader import download\n",
    "\n",
    "from statsforecast.models import AutoETS, ETS, Theta, AutoCES\n",
    "\n",
    "from metrics import SMAPE, MAPE, CRPS\n",
    "\n",
    "RESULTS_DIR = './results'\n",
    "# MANDATORY_TESTING_QUANTS = [0.5, 0.001, 0.01, 0.05, 0.1, 0.25, 0.75, 0.9, 0.95, 0.99, 0.999]\n",
    "MANDATORY_TESTING_QUANTS = np.concatenate([[0.5], [0.001], np.arange(0.01,0.5,0.01), np.arange(0.51,1,0.01), [0.999]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5037c0d0-8965-4e37-9a0d-56aafbf3eb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def marfe(df, actuals_col=\"actuals\", predictions_col=\"predictions\", quantiles_col=\"quants\", bin_size=0.001):\n",
    "    df_cpy = df[[actuals_col, predictions_col, quantiles_col]].reset_index(drop=True).copy()\n",
    "    \n",
    "    df_cpy[\"quants_bins\"] = np.round(df_cpy[quantiles_col], int(np.log10(1/bin_size))).values\n",
    "    df_cpy[\"ReFr\"] = df_cpy[actuals_col] < df_cpy[predictions_col]\n",
    "    refr = df_cpy.groupby('quants_bins')[\"ReFr\"].mean()\n",
    "    # refr.drop([0.0, 1.0], inplace=True)\n",
    "    return np.mean(np.abs(refr.values - refr.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74571386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eee45cee3b554d5882750aada1966373",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ts \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m35\u001b[39m)):\n\u001b[1;32m     19\u001b[0m     paths \u001b[38;5;241m=\u001b[39m glob(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(root_path, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124me\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mw*_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mts\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pickle\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m---> 20\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_pickle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpaths\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;66;03m# Remove rows corresponding to the nan values in actuals, implying invalid ground truth observations\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     num_nulls[ts] \u001b[38;5;241m=\u001b[39m num_nulls\u001b[38;5;241m.\u001b[39mget(ts, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m+\u001b[39m df\u001b[38;5;241m.\u001b[39mactuals\u001b[38;5;241m.\u001b[39misnull()\u001b[38;5;241m.\u001b[39msum()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/reshape/concat.py:382\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 382\u001b[0m op \u001b[38;5;241m=\u001b[39m \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/reshape/concat.py:445\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverify_integrity \u001b[38;5;241m=\u001b[39m verify_integrity\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;241m=\u001b[39m copy\n\u001b[0;32m--> 445\u001b[0m objs, keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_clean_keys_and_objs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;66;03m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[1;32m    448\u001b[0m ndims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_ndims(objs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/reshape/concat.py:507\u001b[0m, in \u001b[0;36m_Concatenator._clean_keys_and_objs\u001b[0;34m(self, objs, keys)\u001b[0m\n\u001b[1;32m    504\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(objs)\n\u001b[1;32m    506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs_list) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 507\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo objects to concatenate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(com\u001b[38;5;241m.\u001b[39mnot_none(\u001b[38;5;241m*\u001b[39mobjs_list))\n",
      "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "# epoch = 4\n",
    "# root_path = os.path.join(RESULTS_DIR, 'MHLV/slawek')\n",
    "\n",
    "epoch = 1\n",
    "root_path = os.path.join(RESULTS_DIR, 'MHLV/NBEATSAQFILM-maxnorm=False-loss=MQNLoss')\n",
    "\n",
    "crps_rnd = CRPS()\n",
    "crps_fixed = CRPS()\n",
    "mape = MAPE()\n",
    "\n",
    "tot_len = 0\n",
    "num_nulls = {}\n",
    "\n",
    "dfs_all = []\n",
    "marfe_ts = []\n",
    "dfs_all_fixed = []\n",
    "df_quants_ts = []\n",
    "for ts in tqdm(range(35)):\n",
    "    paths = glob(os.path.join(root_path, f'e{epoch}w*_{ts}.pickle'))\n",
    "    df = pd.concat([pd.read_pickle(p) for p in paths], axis=1)\n",
    "    # Remove rows corresponding to the nan values in actuals, implying invalid ground truth observations\n",
    "    num_nulls[ts] = num_nulls.get(ts, 0) + df.actuals.isnull().sum()\n",
    "    df = df[~df.actuals.isnull()]\n",
    "    \n",
    "    df['predictions'] = df[df.columns[df.columns.str.startswith('forec')]].mean(axis=1).values\n",
    "    \n",
    "    mandatory_quants = df.quants.isin(np.array(MANDATORY_TESTING_QUANTS))\n",
    "    df_rnd = df[~mandatory_quants]\n",
    "    df_fixed = df[mandatory_quants]\n",
    "    \n",
    "    crps_rnd.update(preds=torch.Tensor(df_rnd['predictions'].values)[None], \n",
    "                    target=torch.Tensor(df_rnd['actuals'].values)[None], \n",
    "                    q=torch.Tensor(df_rnd['quants'].values)[None])\n",
    "    \n",
    "    crps_fixed.update(preds=torch.Tensor(df_fixed['predictions'].values)[None], \n",
    "                      target=torch.Tensor(df_fixed['actuals'].values)[None], \n",
    "                      q=torch.Tensor(df_fixed['quants'].values)[None])\n",
    "    \n",
    "    \n",
    "    median_quants = df_fixed.quants.isin(np.array([0.5]))\n",
    "    mape.update(target=torch.Tensor(df_fixed['actuals'][median_quants].values),\n",
    "                preds=torch.Tensor(df_fixed['predictions'][median_quants].values))\n",
    "    \n",
    "    tot_len += len(df)\n",
    "    dfs_all.append(df_rnd)\n",
    "    dfs_all_fixed.append(df_fixed)\n",
    "\n",
    "    marfe_ts.append(marfe(df_fixed, bin_size=0.01))\n",
    "\n",
    "    df_quants = df_fixed[['actuals','predictions','quants']].copy()\n",
    "    df_quants[ts] = df_quants['actuals'] < df_quants['predictions']\n",
    "    df_quants_ts.append(df_quants.groupby('quants')[ts].mean())\n",
    "\n",
    "df_quants_ts = pd.concat(df_quants_ts, axis=1).T\n",
    "dfs_all = pd.concat(dfs_all)\n",
    "dfs_all_fixed = pd.concat(dfs_all_fixed)\n",
    "print(\"CRPS random quants\", crps_rnd.compute().cpu().numpy())\n",
    "print(\"CRPS mandatory quants\", crps_fixed.compute().cpu().numpy())\n",
    "print(\"MAPE\", mape.compute().cpu().numpy())\n",
    "print(\"MARFE\", marfe(dfs_all, bin_size=0.01))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da447ee8-8f1d-4e93-b44b-441ba14ac6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quants_ts.to_excel('results/df_quants_ts.xlsx')\n",
    "df_quants_ts.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b82e63-61a8-4da7-9d52-0f100ccaab68",
   "metadata": {},
   "outputs": [],
   "source": [
    "marfe(dfs_all, bin_size=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c818e0d-42f0-4cf1-92c3-165765aa8267",
   "metadata": {},
   "outputs": [],
   "source": [
    "marfe(dfs_all_fixed, bin_size=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcace962-1e25-4cba-82fb-64267b42c8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(marfe_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2187d650-6aac-454f-a63d-ab732ea36fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(df_quants_ts - np.array(df_quants_ts.columns)[None]).values.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfb664e-aff6-4179-9439-bf8e311772fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Grzegorz = pd.read_excel('results/Grzegorz/RF.xlsx', header=None)\n",
    "df_Grzegorz.columns = df_quants_ts.columns[1:-1]\n",
    "\n",
    "np.abs(df_Grzegorz - np.array(df_Grzegorz.columns)[None]).values.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75038d2-fe7c-44f8-b655-487a4e7b3c38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0306bee5-113a-4149-9de0-b684134eb42c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f36221a-6798-429c-a7e7-b54758247434",
   "metadata": {},
   "source": [
    "## Analyze Pawel's results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f932f0-4053-4ac5-9203-ae48e198ccc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = os.path.join(RESULTS_DIR, 'pawel')\n",
    "algo = 'dotm'\n",
    "bin_size = 0.001\n",
    "\n",
    "dfs_all = []\n",
    "marfe_ts = []\n",
    "for ts in tqdm(range(35)):\n",
    "    df = pd.read_pickle(os.path.join(root_path, f'{algo}_{ts}.pickle'))\n",
    "    df = df[~df.actuals.isnull()]\n",
    "\n",
    "    mandatory_quants = df.quants.isin(np.array(MANDATORY_TESTING_QUANTS))\n",
    "    df_rnd = df[~mandatory_quants]\n",
    "\n",
    "    dfs_all.append(df_rnd)\n",
    "    \n",
    "    marfe_ts.append(marfe(df_rnd, predictions_col=\"aggForec\", bin_size=bin_size))\n",
    "\n",
    "dfs_all = pd.concat(dfs_all)\n",
    "\n",
    "print(f\"MARFE {algo}\", marfe(dfs_all, predictions_col=\"aggForec\", bin_size=bin_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de91651-1419-4e0d-b7eb-ec87ff12685a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MARFE dotm 0.0207857571455102\n",
    "MARFE snaive 0.03546889814622456\n",
    "MARFE arima 0.025583501139113167\n",
    "MARFE mlp 0.01721498534369242"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f95c231-e78e-4919-92c6-3719a63c4e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls results/pawel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d892cf-ca6f-458b-83ff-07dbaf07b651",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(marfe_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868ea66b-5a32-4f3d-abba-8f99861ddb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_all.quants.hist(bins=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2d0e97-ef9f-4674-8462-1e0ead06ab09",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_all.quants.hist(bins=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c40f420-3d2a-4f65-a66b-5db1b712e06e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
